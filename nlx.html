<!DOCTYPE html><html lang="en" class="" style="scroll-padding:0"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Integrative literature demonstration - The Future of Scientific Literature: Papers Talking to Each Other</title><meta property="og:title" content="Integrative literature demonstration - The Future of Scientific Literature: Papers Talking to Each Other"/><meta name="generator" content="mystmd"/><meta name="keywords" content="reproducible publishing, mystmd, next-gen preprints"/><meta name="image" content="alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.webp"/><meta property="og:image" content="alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.webp"/><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="alienx/build/_assets/app-SAMZOEBT.css"/><link rel="stylesheet" href="alienx/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="/myst-theme.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="fixed top-4 right-4 z-50"><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode." aria-label="Toggle theme between light and dark mode."><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button></div><article class="article content article-left-grid subgrid-gap"><div class="hidden"></div><header class="relative col-screen"><div class="absolute article-left-grid subgrid-gap col-screen bg-no-repeat bg-cover bg-top w-full h-full -z-10 pointer-events-none" style="background-image:url(alienx/build/banner-d71043b95cb3b31e641f661aa1e79bb9.jpg)"></div><div class="w-full relative col-screen article article-left-grid subgrid-gap my-[2rem] pb-[1rem] md:my-[4rem]"><div class="col-page-right shadow-2xl bg-white/80 dark:bg-black/80 backdrop-blur"><div class="flex w-full align-middle py-2 mb-[1rem] text-sm px-4 w-full bg-white/80 dark:bg-black/80 col-page-right"><div class="flex-none pr-2 smallcaps">Living Preprint</div><div class="flex-none mr-2 hidden pl-2 border-l md:block"><span class="font-semibold smallcaps">Neurolibre</span></div><div class="flex-grow"></div><div class="hidden sm:block"><a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener noreferrer" class="opacity-50 hover:opacity-100 text-inherit hover:text-inherit" aria-label="Content License: Creative Commons Attribution 4.0 International (CC-BY-4.0)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mx-1"><title>Content License: Creative Commons Attribution 4.0 International (CC-BY-4.0)</title><path d="M12 2.2c2.7 0 5 1 7 2.9.9.9 1.6 2 2.1 3.1.5 1.2.7 2.4.7 3.8 0 1.3-.2 2.6-.7 3.8-.5 1.2-1.2 2.2-2.1 3.1-1 .9-2 1.7-3.2 2.2-1.2.5-2.5.7-3.7.7s-2.6-.3-3.8-.8c-1.2-.5-2.2-1.2-3.2-2.1s-1.6-2-2.1-3.2-.8-2.4-.8-3.7c0-1.3.2-2.5.7-3.7S4.2 6 5.1 5.1C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C5.6 7.1 5 8 4.6 9c-.4 1-.6 2-.6 3s.2 2.1.6 3c.4 1 1 1.8 1.8 2.6S8 19 9 19.4c1 .4 2 .6 3 .6s2.1-.2 3-.6c1-.4 1.9-1 2.7-1.8 1.5-1.5 2.3-3.3 2.3-5.6 0-1.1-.2-2.1-.6-3.1-.4-1-1-1.8-1.7-2.6C16.1 4.8 14.2 4 12 4zm-.1 6.4l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.5.3-1 .4-1.5.4-.9 0-1.6-.3-2.1-.8-.5-.6-.8-1.3-.8-2.3 0-.9.3-1.7.8-2.2.6-.6 1.3-.8 2.1-.8 1.2 0 2.1.4 2.6 1.4zm5.6 0l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.4.2-.9.3-1.4.3-.9 0-1.6-.3-2.1-.8s-.8-1.3-.8-2.2c0-.9.3-1.7.8-2.2.5-.5 1.2-.8 2-.8 1.2 0 2.1.4 2.6 1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Credit must be given to the creator</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.8-1.7-2.8-4-2.8-6.7s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4zm2.6 5.6v4h-1.1v4.7h-3v-4.7H9.4v-4c0-.2.1-.3.2-.4.1-.2.2-.2.4-.2h4c.2 0 .3.1.4.2.2.1.2.2.2.4zm-4-2.5c0-.9.5-1.4 1.4-1.4s1.4.5 1.4 1.4c0 .9-.5 1.4-1.4 1.4s-1.4-.5-1.4-1.4z"></path></svg></a><a href="https://en.wikipedia.org/wiki/Open_access" target="_blank" rel="noopener noreferrer" title="Open Access" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="mr-1 inline-block opacity-60 hover:opacity-100 hover:text-[#E18435]"><path d="M17.1 12.6h-2V7.5c0-1.7-1.4-3.1-3-3.1-.8 0-1.6.3-2.2.9-.6.5-.9 1.3-.9 2.2v.7H7v-.7c0-1.4.5-2.7 1.5-3.7s2.2-1.5 3.6-1.5 2.6.5 3.6 1.5 1.5 2.3 1.5 3.7v5.1z"></path><path d="M12 21.8c-.8 0-1.6-.2-2.3-.5-.7-.3-1.4-.8-1.9-1.3-.6-.6-1-1.2-1.3-2-.3-.8-.5-1.6-.5-2.4s.2-1.6.5-2.4c.3-.7.7-1.4 1.3-2s1.2-1 1.9-1.3c.7-.3 1.5-.5 2.3-.5.8 0 1.6.2 2.3.5.7.3 1.4.8 1.9 1.3.6.6 1 1.2 1.3 2 .3.8.5 1.6.5 2.4s-.2 1.6-.5 2.4c-.3.7-.7 1.4-1.3 2-.6.6-1.2 1-1.9 1.3-.7.3-1.5.5-2.3.5zm0-10.3c-2.2 0-4 1.8-4 4.1s1.8 4.1 4 4.1 4-1.8 4-4.1-1.8-4.1-4-4.1z"></path><circle cx="12" cy="15.6" r="1.7"></circle></svg></a><a href="https://github.com/agahkarakuzu/alienx" title="GitHub Repository: agahkarakuzu/alienx" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a></div></div><div class="flex flex-col mb-10 md:flex-row"><div id="skip-to-frontmatter" aria-label="article frontmatter" class="flex-grow pt-6 px-6 col-body"><h1 class="mb-0">The Future of Scientific Literature: Papers Talking to Each Other</h1><p class="mt-2 mb-0 lead text-zinc-600 dark:text-zinc-400">A NeuroLibre Case Study</p><div><span class="font-semibold text-sm inline-block"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R1oqf8p:" data-state="closed">Agah Karakuzu</button><a class="ml-1" href="https://orcid.org/0000-0001-7283-271X" target="_blank" rel="noopener noreferrer" title="ORCID (Open Researcher and Contributor ID)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1rem" height="1rem" class="inline-block text-gray-400 hover:text-[#A9C751] -translate-y-[0.1em]"><path d="M21.8 12c0 5.4-4.4 9.8-9.8 9.8S2.2 17.4 2.2 12 6.6 2.2 12 2.2s9.8 4.4 9.8 9.8zM8.2 5.8c-.4 0-.8.3-.8.8s.3.8.8.8.8-.4.8-.8-.3-.8-.8-.8zm2.3 9.6h1.2v-6h1.8c2.3 0 3.3 1.4 3.3 3s-1.5 3-3.3 3h-3v1.1H9V8.3H7.7v8.2h5.9c3.3 0 4.5-2.2 4.5-4.1s-1.2-4.1-4.3-4.1h-3.2l-.1 7.1z"></path></svg></a></span></div><div class="flex mt-2 text-sm font-light"><div class="flex-none" title="DOI (Digital Object Identifier)"><a class="font-light no-underline hover:font-light hover:underline text-inherit hover:text-inherit" target="_blank" rel="noopener noreferrer" href="https://doi.org/10.55458/neurolibre.alienx">https://doi.org/10.55458/neurolibre.alienx</a></div></div></div><div class="pt-5 md:self-center h-fit lg:pt-0 col-body lg:col-margin-right-inset"><div class="col-margin mt-3 mx-5 lg:mt-2 lg:mx-0 lg:w-[300px]"><div class="flex flex-wrap gap-2 lg:flex-col w-[147px] pl-[1px] lg:mx-auto"><button class="inline-flex items-center mr-2 font-medium no-underline text-gray-900 lg:mr-0 lg:flex" title="Click to start a new compute session"><div class="flex items-center h-full"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="inline h-5 pr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg><span>Launch Jupyter</span></div></button></div></div></div></div></div></div></header><main id="main" class="article-left-grid subgrid-gap col-screen"><div class="flex items-center p-3 mb-10 border-y bg-slate-50 dark:bg-slate-600 border-y-slate-300 col-screen"><a class="flex gap-1 px-2 py-1 font-normal no-underline border rounded bg-slate-200 border-slate-600 hover:bg-slate-800 hover:text-white hover:border-transparent" href="/alienx"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1rem" height="1rem" class="self-center flex-none transition-transform group-hover:-translate-x-1"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><span>Back to Article</span></a><div class="flex-grow text-center">Integrative literature demonstration</div><div class="mr-2"><button class="flex gap-1 px-2 py-1 font-normal no-underline border rounded bg-slate-200 border-slate-600 hover:bg-slate-800 hover:text-white hover:border-transparent" title="Click to start a new compute session"><div class="flex items-center h-full"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1rem" height="1rem" class="self-center mr-2 transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg><span>Launch Jupyter</span></div></button></div><a href="alienx/build/nlx-1b90d8a36f5054a3087ec0953ae32b69.ipynb" class="flex gap-1 px-2 py-1 font-normal no-underline border rounded bg-slate-200 border-slate-600 hover:bg-slate-800 hover:text-white hover:border-transparent"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1rem" height="1rem" class="self-center flex-none transition-transform group-hover:-translate-x-1"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m.75 12 3 3m0 0 3-3m-3 3v-6m-1.5-9H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9Z"></path></svg><span>Download <!-- -->Notebook</span></a></div><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-5"><h1 class="mb-0">Integrative literature demonstration</h1></div><div class="block my-10 lg:sticky lg:top-0 lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:24px"><nav><div class="my-4 text-sm leading-6 uppercase text-slate-900 dark:text-slate-100">Supporting Documents</div><ul class="flex flex-col gap-2 pl-0 text-sm leading-6 list-none text-slate-700 dark:text-slate-300"><li><a class="no-underline flex self-center hover:text-blue-700" href="/alienx/nlx#main"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline mr-2 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25M9 16.5v.75m3-3v3M15 12v5.25m-4.5-15H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9Z"></path></svg><span>Integrative literature demonstration</span></a></li></ul></nav></div><div id="skip-to-article"></div><div id="fwY7LOj3rh" class="relative group/block article-left-grid subgrid-gap col-screen"><h5 id="neurolibre-day-september-27-2024-montreal-canada" class="relative group"><span class="mr-3 select-none">0.0.0.1</span><span class="heading-text">NeuroLibre Day | September 27, 2024 | Montreal, Canada</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#neurolibre-day-september-27-2024-montreal-canada" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h5><h3 id="a-meta-analysis-on-5-alberta-alien-brain-extraction-analytics-articles" class="relative group"><span class="mr-3 select-none">0.1</span><span class="heading-text">A meta-analysis on 5 ALBERTA (ALien Brain ExtRacTion Analytics) articles</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#a-meta-analysis-on-5-alberta-alien-brain-extraction-analytics-articles" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h3><ul><li><a target="_blank" href="https://agahkarakuzu.github.io/alienpaper1" rel="noreferrer">The Role of Hippocampal Volume, Brain Density, and Network Efficiency in Alien Memory Function</a></li><li><a target="_blank" href="https://agahkarakuzu.github.io/alienpaper2" rel="noreferrer">Size Matters, but So Does Connectivity: The Amygdalaâ€™s Role in Emotional Intelligence</a></li><li><a target="_blank" href="https://agahkarakuzu.github.io/alienpaper3" rel="noreferrer">More Than Just Words: Temporal Cortex Volume Correlates with Language Ability</a></li><li><a target="_blank" href="https://agahkarakuzu.github.io/alienpaper4" rel="noreferrer">Navigating the Void: How Parietal Cortex Volume Predicts Spatial Orientation in Zero Gravity</a></li><li><a target="_blank" href="https://agahkarakuzu.github.io/alienpaper5" rel="noreferrer">Attention is all you need, and a chunky prefrontal cortex</a></li></ul></div><div id="zTdtVmwi01" class="relative group/block article-left-grid subgrid-gap col-screen"><h3 id="neurolibre-cross-links" class="relative group"><span class="mr-3 select-none">0.2</span><span class="heading-text">NeuroLibre cross-links</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#neurolibre-cross-links" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h3><p><picture><source srcSet="alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.webp" type="image/webp"/><img id="QxnFZvU1En" style="margin:0 auto" src="alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.png" data-canonical-url="https://github.com/neurolibre/brand/blob/main/png/neuroxlink.png?raw=true"/></picture></p><p>NeuroxLink is a mini python package to parse <a target="_blank" href="https://github.com/syntax-tree/mdast" rel="noreferrer">mdast</a>, facilitating cross-paper import of article content from <abbr aria-label="Markedly Structured Markdown" class="border-b border-dotted cursor-help" data-state="closed">MyST</abbr> servers. It also introduces some <a target="_blank" href="https://plotly.com" rel="noreferrer">Plotly</a> functionality to work with data from interactive figures!</p><p><code>pip install neuroxlink</code></p><p><a target="_blank" href="https://badge.fury.io/py/neuroxlink" rel="noreferrer"><img id="nkLwyiV72t" style="margin:0 auto" src="alienx/build/2e475989b921a2bac562b9b20ada7789.svg" alt="PyPI version" data-canonical-url="https://badge.fury.io/py/neuroxlink.svg"/></a></p><h3 id="nlx-neuroxlink-nlx-import-paper-10-55458-neurolibre-alberta1" class="relative group"><span class="mr-3 select-none">0.3</span><span class="heading-text"><code>nlx = NeuroxLink()</code><br/><br/><code>nlx.import_paper(&quot;10.55458/neurolibre.alberta1&quot;)</code></span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#nlx-neuroxlink-nlx-import-paper-10-55458-neurolibre-alberta1" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h3></div><div id="Bl6hVVu6t4" class="relative group/block article-left-grid subgrid-gap col-screen"><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre"># from neuroxlink.src.neuroxlink import NeuroxLink
from neuroxlink import NeuroxLink</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="iMnuNP-9rc-WoUIM3Zr7K" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="B25Xx4XDiL" class="relative group/block article-left-grid subgrid-gap col-screen"><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">import sys
import os
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.io as pio
import numpy as np
pio.renderers.default = &quot;plotly_mimetype&quot;
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="K0nSwBQr3J5spO54Z60uj" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="GfZhgcIjRE" class="relative group/block article-left-grid subgrid-gap col-screen"><h4 id="id-1-instantiate-a-neuroxlink-object-nlx-and-import-the-mri-review-article" class="relative group"><span class="mr-3 select-none">0.3.1</span><span class="heading-text">1. Instantiate a <code>neuroxlink</code> object (<code>nlx</code>) and import the MRI review article</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#id-1-instantiate-a-neuroxlink-object-nlx-and-import-the-mri-review-article" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h4></div><div id="xV3mVJ27Pw" class="relative group/block article-left-grid subgrid-gap col-screen"><div id="fig1cell-code" class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">nlx = NeuroxLink(cdn_url=&quot;https://cdn.neurolibre.org&quot;)
nlx.import_papers(&quot;10.55458/neurolibre.00021&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div id="fig1cell-output" data-mdast-node-id="RsgCmttt9OWFNHA5kg_IS" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>ðŸ”— importing 10.55458/neurolibre.00021 from ðŸŒŽ https://cdn.neurolibre.org/content/mriscope/intro.json
Reproducible research practices in magnetic resonance neuroimaging: A review informed by advanced language models
-------------------------------------
</span></code></pre></div></div></div><div id="hgexQT7Tre" class="relative group/block article-left-grid subgrid-gap col-screen"><h4 id="id-2-access-some-information-about-the-article" class="relative group"><span class="mr-3 select-none">0.3.2</span><span class="heading-text">2. Access some information about the article</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#id-2-access-some-information-about-the-article" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h4></div><div id="eaGMcXNeRF" class="relative group/block article-left-grid subgrid-gap col-screen"><div id="fig2cell-code" class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">paper = nlx.papers[0]
print(&quot;\n------------&gt; AUTHORS AND AFFILIATIONS&quot;)
print(paper.get_authors(), &quot;\n------------&gt; DEPENDENCIES&quot;)
print(paper.get_dependencies(), &quot;\n------------&gt; HEADINGS&quot;)
print(paper.headings)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div id="fig2cell-output" data-mdast-node-id="21UJFKBnGUNSIxWD-gzU7" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>
------------&gt; AUTHORS AND AFFILIATIONS
[{&#x27;nameParsed&#x27;: {&#x27;literal&#x27;: &#x27;Agah Karakuzu&#x27;, &#x27;given&#x27;: &#x27;Agah&#x27;, &#x27;family&#x27;: &#x27;Karakuzu&#x27;}, &#x27;name&#x27;: &#x27;Agah Karakuzu&#x27;, &#x27;orcid&#x27;: &#x27;0000-0001-7283-271X&#x27;, &#x27;affiliations&#x27;: [&#x27;NeuroPoly, Polytechnique Montreal, Quebec, Canada&#x27;, &#x27;Montreal Heart Institute, Montreal, Quebec, Canada&#x27;], &#x27;id&#x27;: &#x27;contributors-myst-generated-uid-0&#x27;}, {&#x27;nameParsed&#x27;: {&#x27;literal&#x27;: &#x27;Mathieu Boudreau&#x27;, &#x27;given&#x27;: &#x27;Mathieu&#x27;, &#x27;family&#x27;: &#x27;Boudreau&#x27;}, &#x27;name&#x27;: &#x27;Mathieu Boudreau&#x27;, &#x27;orcid&#x27;: &#x27;0000-0002-7726-4456&#x27;, &#x27;affiliations&#x27;: [&#x27;NeuroPoly, Polytechnique Montreal, Quebec, Canada&#x27;], &#x27;id&#x27;: &#x27;contributors-myst-generated-uid-1&#x27;}, {&#x27;nameParsed&#x27;: {&#x27;literal&#x27;: &#x27;Nikola Stikov&#x27;, &#x27;given&#x27;: &#x27;Nikola&#x27;, &#x27;family&#x27;: &#x27;Stikov&#x27;}, &#x27;name&#x27;: &#x27;Nikola Stikov&#x27;, &#x27;orcid&#x27;: &#x27;0000-0002-8480-5230&#x27;, &#x27;affiliations&#x27;: [&#x27;NeuroPoly, Polytechnique Montreal, Quebec, Canada&#x27;, &#x27;Montreal Heart Institute, Montreal, Quebec, Canada&#x27;, &#x27;Center for Advanced Interdisciplinary Research, Ss. Cyril and Methodius University, Skopje, North Macedonia&#x27;], &#x27;id&#x27;: &#x27;contributors-myst-generated-uid-2&#x27;}] 
------------&gt; DEPENDENCIES
[{&#x27;url&#x27;: &#x27;/mriscope/literature-overview&#x27;, &#x27;label&#x27;: &#x27;fig1-cell&#x27;, &#x27;kind&#x27;: &#x27;Notebook&#x27;, &#x27;slug&#x27;: &#x27;literature-overview&#x27;, &#x27;location&#x27;: &#x27;/content/literature_overview.ipynb&#x27;, &#x27;title&#x27;: &#x27;Literature overview&#x27;}, {&#x27;url&#x27;: &#x27;/mriscope/gpt-insights&#x27;, &#x27;label&#x27;: &#x27;gptsession&#x27;, &#x27;kind&#x27;: &#x27;Notebook&#x27;, &#x27;slug&#x27;: &#x27;gpt-insights&#x27;, &#x27;location&#x27;: &#x27;/content/gpt_insights.ipynb&#x27;, &#x27;title&#x27;: &#x27;Creating a knowledge base for a custom GPT&#x27;}, {&#x27;url&#x27;: &#x27;/mriscope/word-cloud&#x27;, &#x27;label&#x27;: &#x27;fig4-cell&#x27;, &#x27;kind&#x27;: &#x27;Notebook&#x27;, &#x27;slug&#x27;: &#x27;word-cloud&#x27;, &#x27;location&#x27;: &#x27;/content/word_cloud.ipynb&#x27;, &#x27;title&#x27;: &#x27;Results&#x27;}] 
------------&gt; HEADINGS
[{&#x27;depth&#x27;: 1, &#x27;text&#x27;: &#x27;Introduction&#x27;, &#x27;identifier&#x27;: &#x27;introduction&#x27;}, {&#x27;depth&#x27;: 1, &#x27;text&#x27;: &#x27;Methodology&#x27;, &#x27;identifier&#x27;: &#x27;methodology&#x27;}, {&#x27;depth&#x27;: 2, &#x27;text&#x27;: &#x27;Mapping selected articles in the semantic landscape of reproducibility&#x27;, &#x27;identifier&#x27;: &#x27;mapping-selected-articles-in-the-semantic-landscape-of-reproducibility&#x27;}, {&#x27;depth&#x27;: 2, &#x27;text&#x27;: &#x27;Creating a knowledge base for a custom  GPT&#x27;, &#x27;identifier&#x27;: &#x27;creating-a-knowledge-base-for-a-custom-gpt&#x27;}, {&#x27;depth&#x27;: 1, &#x27;text&#x27;: &#x27;Results&#x27;, &#x27;identifier&#x27;: &#x27;results&#x27;}, {&#x27;depth&#x27;: 2, &#x27;text&#x27;: &#x27;Contextual placement of the selected articles in the landscape of reproducibility&#x27;, &#x27;identifier&#x27;: &#x27;contextual-placement-of-the-selected-articles-in-the-landscape-of-reproducibility&#x27;}, {&#x27;depth&#x27;: 2, &#x27;text&#x27;: &#x27;Custom  GPT  for reproducibility insights&#x27;, &#x27;identifier&#x27;: &#x27;custom-gpt-for-reproducibility-insights&#x27;}, {&#x27;depth&#x27;: 3, &#x27;text&#x27;: &#x27;GPT -powered summary of the reproducible magnetic resonance neuroimaging&#x27;, &#x27;identifier&#x27;: &#x27;gpt-powered-summary-of-the-reproducible-magnetic-resonance-neuroimaging&#x27;}, {&#x27;depth&#x27;: 4, &#x27;text&#x27;: &#x27;Data sharing&#x27;, &#x27;identifier&#x27;: &#x27;data-sharing&#x27;}, {&#x27;depth&#x27;: 4, &#x27;text&#x27;: &#x27;Code sharing&#x27;, &#x27;identifier&#x27;: &#x27;code-sharing&#x27;}, {&#x27;depth&#x27;: 4, &#x27;text&#x27;: &#x27;Vendor-neutrality&#x27;, &#x27;identifier&#x27;: &#x27;vendor-neutrality&#x27;}, {&#x27;depth&#x27;: 4, &#x27;text&#x27;: &#x27;Dissemination&#x27;, &#x27;identifier&#x27;: &#x27;dissemination&#x27;}, {&#x27;depth&#x27;: 1, &#x27;text&#x27;: &#x27;Discussion and Future Directions&#x27;, &#x27;identifier&#x27;: &#x27;discussion-and-future-directions&#x27;}]
</span></code></pre></div></div></div><div id="S2yGQjfKer" class="relative group/block article-left-grid subgrid-gap col-screen"><h4 id="id-3-import-interactive-figures-as-structure-data-and-create-plotly-objects" class="relative group"><span class="mr-3 select-none">0.3.3</span><span class="heading-text">3. Import interactive figures as structure data and create Plotly objects!</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#id-3-import-interactive-figures-as-structure-data-and-create-plotly-objects" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h4><p>First, we will check if the article published any plotly figures:</p></div><div id="xy8glVkwyS" class="relative group/block article-left-grid subgrid-gap col-screen"><div id="fig3inspect-code" class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">paper.inspect_plotly_figures()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div id="fig3inspect-output" data-mdast-node-id="eLaepKWAD8sTPic-OjNnL" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>These are the plotly figures I found:
-------------------------------------
- html-link [fig1] enumerated as (Figure 2)

- html-link [fig2] enumerated as (Figure 3)

- html-link [fig4] enumerated as (Figure 6)

</span></code></pre></div></div></div><div id="ZD9B6R1IID" class="relative group/block article-left-grid subgrid-gap col-screen"><p>Perfect! There are three plotly figures that were linked using <code>fig1</code>, <code>fig2</code>, and <code>fig4</code>. Lets fetch interactive Figure 1 and render it.</p><p>Note that <strong>we are not performing any computation here</strong>, instead, <strong>we are taking a special chunk of the paper we imported as structured data and creating a plotly figure out of it</strong>!</p></div><div id="KSXJ1pBDEC" class="relative group/block article-left-grid subgrid-gap col-screen"><div id="fig3cell-code" class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">fig = paper.create_plotly_object_from(&#x27;fig2&#x27;)
fig.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div id="fig3cell-output" data-mdast-node-id="bPwf5-igjXK7fe5Xoe70h" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="hnfp2kVYcs" class="relative group/block article-left-grid subgrid-gap col-screen"><h4 id="id-4-now-capture-the-data" class="relative group"><span class="mr-3 select-none">0.3.4</span><span class="heading-text">4. Now, capture the data!</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#id-4-now-capture-the-data" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h4><p>We can treat Plotly as our data standard for interactive figures. Behind the scenes, neuroxlink is parsing these plotly objects to return as the part we are interested in!</p></div><div id="Z70MJPiYxh" class="relative group/block article-left-grid subgrid-gap col-screen"><div id="fig4cell-code" class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">data = paper.get_plotly_data(&#x27;fig2&#x27;)
data.head()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div id="fig4cell-output" data-mdast-node-id="vtGl-2ShhXDEwvoGAMHLt" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="g9TX53tR2L" class="relative group/block article-left-grid subgrid-gap col-screen"><hr class="py-2 my-5 translate-y-2"/><h2 id="now-we-are-talking-or-is-it-papers-talking-to-each-other" class="relative group"><span class="mr-3 select-none">1</span><span class="heading-text">Now we are talking! Or, is it papers talking to each other?</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#now-we-are-talking-or-is-it-papers-talking-to-each-other" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h2><p><code>#TalkAboutInsight</code></p><h4 id="lets-run-a-meta-analysis-by-importing-15-figures-from-5-alberta-studies-into-this-article" class="relative group"><span class="mr-3 select-none">1.0.1</span><span class="heading-text">Letâ€™s run a meta-analysis by importing 15 figures from 5 ALBERTA studies into this article!</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#lets-run-a-meta-analysis-by-importing-15-figures-from-5-alberta-studies-into-this-article" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h4><p><picture><source srcSet="alienx/build/4cabc802da2871bc3a250b0559827635.webp" type="image/webp"/><img id="fUoIzmdXzk" style="margin:0 auto" src="alienx/build/4cabc802da2871bc3a250b0559827635.jpeg" data-canonical-url="https://github.com/agahkarakuzu/alienpaper1/blob/main/static/banner.jpg?raw=true"/></picture></p></div><div id="IC8CkCxdoK" class="relative group/block article-left-grid subgrid-gap col-screen"><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre"># Define and create a list of DOIs and figures
doi1 = &quot;10.55458/neurolibre.alberta1&quot;
doi2 = &quot;10.55458/neurolibre.alberta2&quot;
doi3 = &quot;10.55458/neurolibre.alberta3&quot;
doi4 = &quot;10.55458/neurolibre.alberta4&quot;
doi5 = &quot;10.55458/neurolibre.alberta5&quot;
dois = [doi1, doi2, doi3, doi4, doi5]
figures = [&#x27;fig1&#x27;, &#x27;fig2&#x27;, &#x27;fig3&#x27;]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="U2RDf6v3asYDtpiT0BC00" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="qE31bx8shw" class="relative group/block article-left-grid subgrid-gap col-screen"><h3 id="import-them-alien-papers" class="relative group"><span class="mr-3 select-none">1.1</span><span class="heading-text">Import them alien papers!</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#import-them-alien-papers" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h3></div><div id="hky0bPKElC" class="relative group/block article-left-grid subgrid-gap col-screen"><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">nlx.import_papers([doi1,doi2,doi3,doi4,doi5])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Bbj0Ml6i--RYIqv2Rlfiz" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>ðŸ”— importing 10.55458/neurolibre.alberta1 from ðŸŒŽ https://cdn.neurolibre.org/content/alberta1/paper.json
The Role of Hippocampal Volume, Brain Density, and Network Efficiency in Alien Memory Function: ALien Brain ExtRacTion Analytics (ALBERTA) Consortium
-------------------------------------
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>ðŸ”— importing 10.55458/neurolibre.alberta2 from ðŸŒŽ https://cdn.neurolibre.org/content/alberta2/paper.json
Size Matters, but So Does Connectivity: The Amygdala&#x27;s Role in Emotional Intelligence: ALien Brain ExtRacTion Analytics (ALBERTA) Consortium
-------------------------------------
ðŸ”— importing 10.55458/neurolibre.alberta3 from ðŸŒŽ https://cdn.neurolibre.org/content/alberta3/paper.json
More Than Just Words: Temporal Cortex Volume Correlates with Language Ability: ALien Brain ExtRacTion Analytics (ALBERTA) Consortium
-------------------------------------
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>ðŸ”— importing 10.55458/neurolibre.alberta4 from ðŸŒŽ https://cdn.neurolibre.org/content/alberta4/paper.json
Navigating the Void: How Parietal Cortex Volume Predicts Spatial Orientation in Zero Gravity: ALien Brain ExtRacTion Analytics (ALBERTA) Consortium
-------------------------------------
ðŸ”— importing 10.55458/neurolibre.alberta5 from ðŸŒŽ https://cdn.neurolibre.org/content/alberta5/paper.json
Attention is all you need, and a chunky prefrontal cortex: ALien Brain ExtRacTion Analytics (ALBERTA) Consortium
-------------------------------------
</span></code></pre></div></div></div><div id="ei3mZD66Hb" class="relative group/block article-left-grid subgrid-gap col-screen"><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">nlx.papers[doi2].inspect_plotly_figures()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="JrbaflUElQS5HinnG7532" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>These are the plotly figures I found:
-------------------------------------
- html-link [fig1] enumerated as (Figure 1)

- html-link [fig2] enumerated as (Figure 2)

- html-link [fig3] enumerated as (Figure 3)

</span></code></pre></div></div></div><div id="cgT8B30XbF" class="relative group/block article-left-grid subgrid-gap col-screen"><h3 id="we-can-dial-into-these-figures" class="relative group"><span class="mr-3 select-none">1.2</span><span class="heading-text">We can dial into these figures!</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#we-can-dial-into-these-figures" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h3><p>Interactive figures can have multiple representations of the data, which is one of the many things that makes them cool. Yet, we can still select the type of data we are interested in and use it!</p></div><div id="dnrCILRUFp" class="relative group/block article-left-grid subgrid-gap col-screen"><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">nlx.papers[&quot;10.55458/neurolibre.alberta2&quot;].create_plotly_object_from(&#x27;fig1&#x27;)
#nlx.papers[&quot;10.55458/neurolibre.alberta2&quot;].create_plotly_object_from(&#x27;fig1&#x27;, select_trace_type=&quot;histogram&quot;)
#nlx.papers[&quot;10.55458/neurolibre.alberta2&quot;].create_plotly_object_from(&#x27;fig1&#x27;, select_trace_type=&quot;box&quot;)
#nlx.papers[&quot;10.55458/neurolibre.alberta2&quot;].create_plotly_object_from(&#x27;fig1&#x27;, select_trace_type=&quot;scatter&quot;)
#nlx.papers[&quot;10.55458/neurolibre.alberta2&quot;].create_plotly_object_from(&#x27;fig1&#x27;, select_trace_type=&quot;scatter&quot;,select_trace_mode=&quot;markers&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="RrYX6wjLDNRbOl5g_oa9k" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="dGbTUblRdD" class="relative group/block article-left-grid subgrid-gap col-screen"><h3 id="start-the-meta-analysis" class="relative group"><span class="mr-3 select-none">1.3</span><span class="heading-text">Start the meta analysis!</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#start-the-meta-analysis" title="Link to this Section" aria-label="Link to this Section">Â¶</a></h3><p>Now we are going to capture the bivariate data of 3 types of measurements (alien brain volume (ABV), alien brain density (ABD), and alien brain efficiency (ABE)) from 15 articles.</p></div><div id="iv6qUfv5gX" class="relative group/block article-left-grid subgrid-gap col-screen"><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">data = []

for doi in dois:
    fig_data = []
    for fig in figures:
        print(f&quot;Fetching data: {fig} from {doi}&quot;)
        fig_data.append(nlx.papers[doi].create_plotly_object_from(fig,select_trace_type=&quot;scatter&quot;,select_trace_mode=&quot;markers&quot;))
    data.append(fig_data)
print(&quot;done&quot;)    </code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="-269bNHFnvknnOnfJ9MO0" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig1 from 10.55458/neurolibre.alberta1
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig2 from 10.55458/neurolibre.alberta1
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig3 from 10.55458/neurolibre.alberta1
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig1 from 10.55458/neurolibre.alberta2
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig2 from 10.55458/neurolibre.alberta2
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig3 from 10.55458/neurolibre.alberta2
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig1 from 10.55458/neurolibre.alberta3
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig2 from 10.55458/neurolibre.alberta3
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig3 from 10.55458/neurolibre.alberta3
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig1 from 10.55458/neurolibre.alberta4
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig2 from 10.55458/neurolibre.alberta4
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig3 from 10.55458/neurolibre.alberta4
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig1 from 10.55458/neurolibre.alberta5
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig2 from 10.55458/neurolibre.alberta5
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>Fetching data: fig3 from 10.55458/neurolibre.alberta5
</span></code></pre></div><div><pre class="text-sm font-thin font-system"><code><span>done
</span></code></pre></div></div></div><div id="q58IT2kW3D" class="relative group/block article-left-grid subgrid-gap col-screen"><div id="fig5cell-code" class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">fig = make_subplots(rows=5, cols=3, subplot_titles=(&quot;ABV&quot;, &quot;ABD&quot;, &quot;ABE&quot;) * 5)

for row in range(5):
    fig.update_yaxes(title_text=f&quot;Score&quot;, row=row+1, col=1)
    fig.update_yaxes(title_text=f&quot;Paper {row+1}&quot;, row=row+1, col=3, side=&quot;right&quot;)
    for col in range(3):
        subplot_figure = data[row][col]
        for trace in subplot_figure.data:
            fig.add_trace(trace, row=row + 1, col=col + 1)
            
# Update layout
fig.update_layout(title_text=&quot;Mosaic Plot of 15 figures from 5 articles&quot;,
                  height=800, width=800,
                  showlegend=True,
                  template=&quot;plotly_dark&quot;)

# Show the figure
fig.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div id="fig5cell-output" data-mdast-node-id="yEjju19LIPfpeYdLHN_Ml" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="lL7yhRX3dP" class="relative group/block article-left-grid subgrid-gap col-screen"><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">column_names = {&#x27;fig1&#x27;: &#x27;vol&#x27;, &#x27;fig2&#x27;: &#x27;dens&#x27;, &#x27;fig3&#x27;: &#x27;eff&#x27;}

# Initialize an empty DataFrame to store the combined data
combined_df = pd.DataFrame()

# Loop through each DOI and figure
for doi in dois:
    data = {}
    for fig in figures:
        # Get the data for the current DOI and figure
        fig_data = nlx.papers[doi].get_plotly_data(fig,select_trace_type=&quot;scatter&quot;,select_trace_mode=&quot;markers&quot;)
        
        #data[&#x27;score&#x27;] = fig_data[&#x27;x&#x27;]
        data[column_names[fig]] = fig_data[&#x27;y&#x27;]
        
    # Create a DataFrame for the current DOI with DOI as a column
    df = pd.DataFrame(data)
    df[&#x27;DOI&#x27;] = doi  # Add the DOI to each row
    
    # Append to the combined DataFrame
    combined_df = pd.concat([combined_df, df], ignore_index=True)

print(combined_df)
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="GQu4wx5xOmXipaOLqUsPE" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>              vol         dens          eff                           DOI
0     1241.856859  1241.856859  1241.856859  10.55458/neurolibre.alberta1
1     -386.257828  -386.257828  -386.257828  10.55458/neurolibre.alberta1
2     1141.903393  1141.903393  1141.903393  10.55458/neurolibre.alberta1
3     2335.390648  2335.390648  2335.390648  10.55458/neurolibre.alberta1
4     -508.642687  -508.642687  -508.642687  10.55458/neurolibre.alberta1
...           ...          ...          ...                           ...
1995    11.076677    11.076677    11.076677  10.55458/neurolibre.alberta5
1996  -517.365866  -517.365866  -517.365866  10.55458/neurolibre.alberta5
1997   565.384082   565.384082   565.384082  10.55458/neurolibre.alberta5
1998    25.591227    25.591227    25.591227  10.55458/neurolibre.alberta5
1999   850.649546   850.649546   850.649546  10.55458/neurolibre.alberta5

[2000 rows x 4 columns]
</span></code></pre></div></div></div><div id="foKu4SipPR" class="relative group/block article-left-grid subgrid-gap col-screen"><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">doi_names = {&#x27;10.55458/neurolibre.alberta1&#x27;: &#x27;Hippocampus&#x27;, &#x27;10.55458/neurolibre.alberta2&#x27;: &#x27;Amygdala&#x27;, &#x27;10.55458/neurolibre.alberta3&#x27;: &#x27;Temporal&#x27;,&quot;10.55458/neurolibre.alberta4&quot;:&quot;Parietal&quot;,&quot;10.55458/neurolibre.alberta5&quot;:&quot;Prefrontal&quot;}

# Initialize an empty DataFrame for combining all DOIs&#x27; data
combined_df = pd.DataFrame()

# Loop through each DOI
for doi in dois:
    data = {}
    
    # Loop through each figure for the current DOI
    for fig in figures:
        # Get the data for the current DOI and figure
        fig_data = nlx.papers[doi].get_plotly_data(fig, select_trace_type=&quot;scatter&quot;, select_trace_mode=&quot;markers&quot;)
        
        # Add data for each figure, ensure the column name is unique
        data[&#x27;score&#x27;] = fig_data[&#x27;y&#x27;]
        data[column_names[fig]] = fig_data[&#x27;x&#x27;]  # Use the figure-specific column name
        
    # Convert the collected data into a DataFrame
    df = pd.DataFrame(data)
    
    # Add the DOI to each row in the DataFrame
    df[&#x27;Region&#x27;] = doi_names[doi]
    
    # Append to the combined DataFrame
    combined_df = pd.concat([combined_df, df], ignore_index=True)

# Print or check the combined DataFrame
combined_df.head()
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="d10qVMMBb9FtPU62jQ6ZA" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="VKFICa4oB6" class="relative group/block article-left-grid subgrid-gap col-screen"><div id="fig6cell-code" class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre"># numeric_cols = combined_df.select_dtypes(include=[np.number]).columns
# df_zscore[numeric_cols] = (combined_df[numeric_cols] - combined_df[numeric_cols].mean())/combined_df[numeric_cols].std()
# df_zscore[&quot;DOI&quot;] = combined_df[&quot;DOI&quot;]

fig = px.scatter_matrix(combined_df,
    dimensions=[&quot;vol&quot;, &quot;dens&quot;, &quot;eff&quot;,&quot;score&quot;],
    color=&quot;Region&quot;, template=&quot;plotly_dark&quot;)
fig.update_traces(diagonal_visible=False)
fig.update_layout(margin=dict(l=0,r=0,t=0,b=0))
fig.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div id="fig6cell-output" data-mdast-node-id="olSXY91ijWdkaBT09ykYh" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="vr0djrj7iO" class="relative group/block article-left-grid subgrid-gap col-screen"><div id="fig7cell-code" class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">features = [&#x27;score&#x27;, &#x27;vol&#x27;, &#x27;dens&#x27;, &#x27;eff&#x27;]
X = combined_df[features].values
X_mean = np.mean(X, axis=0)
X_std = X - X_mean
cov_matrix = np.cov(X_std.T)
eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)
sorted_indices = np.argsort(eigenvalues)[::-1]
sorted_eigenvalues = eigenvalues[sorted_indices]
sorted_eigenvectors = eigenvectors[:, sorted_indices]

top_2_eigenvectors = sorted_eigenvectors[:, :2]
X_pca = X_std.dot(top_2_eigenvectors)

pca_df = pd.DataFrame(data=X_pca, columns=[&#x27;PCA1&#x27;, &#x27;PCA2&#x27;])
pca_df[&#x27;Region&#x27;] = combined_df[&#x27;Region&#x27;]

fig = px.scatter(pca_df, x=&#x27;PCA1&#x27;, y=&#x27;PCA2&#x27;, color=&#x27;Region&#x27;, title=&#x27;PCA of Regions based on Features&#x27;, template=&quot;plotly_dark&quot;)
fig.update_traces(marker=dict(size=15, opacity=0.7))
fig.update_layout(margin=dict(l=0,r=0,t=0,b=0))
fig.show()
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div id="fig7cell-output" data-mdast-node-id="BmshJvWzDD8A96tWZCUGb" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="VaW6M3RrFa" class="relative group/block article-left-grid subgrid-gap col-screen"><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre"># If you don&#x27;t believe me that the variability is coming from volume and score...

# Aliens are soo linear, omg. Just stick with the ones with bigger heads :) </code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="pBUdH9LSOSoeVQtWpwE4b" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="kSnKDtvHxX" class="relative group/block article-left-grid subgrid-gap col-screen"><div id="fig8cell-code" class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">fig = px.scatter(combined_df,x=&quot;vol&quot;,y=&quot;score&quot;,color=&quot;Region&quot;,template=&quot;plotly_dark&quot;)
fig.update_traces(marker=dict(size=15, opacity=0.7))
fig.update_layout(margin=dict(l=0,r=0,t=0,b=0))
fig.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div id="fig8cell-output" data-mdast-node-id="AxDFZ5JbpngyKTdHNFilw" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="sPW5nFn5H6" class="relative group/block article-left-grid subgrid-gap col-screen"><div id="fig9cell-code" class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre style="display:block;overflow-x:auto;padding:0.8rem;background:#1E1E1E;color:#DCDCDC"><code class="language-python" style="white-space:pre">score_corr_pearson = combined_df.corr(numeric_only=True, method=&quot;pearson&quot;)
score_corr_kendall = combined_df.corr(numeric_only=True, method=&quot;kendall&quot;)
score_corr_spearman = combined_df.corr(numeric_only=True, method=&quot;spearman&quot;)

# Create a list of the correlation matrices and corresponding labels
corr_matrices = [score_corr_pearson, score_corr_kendall, score_corr_spearman]
methods = [&#x27;Pearson&#x27;, &#x27;Kendall&#x27;, &#x27;Spearman&#x27;]

# Initialize the first heatmap (Pearson by default)
fig = px.imshow(corr_matrices[0],
                color_continuous_scale=&#x27;Viridis&#x27;,
                zmin=-0.5, zmax=0.9, 
                title=f&#x27;{methods[0]} Correlation Matrix&#x27;, template=&quot;ggplot2&quot;)

# Update the layout to add the slider
fig.update_layout(
    updatemenus=[
        dict(
            type=&quot;buttons&quot;,
            direction=&quot;down&quot;,
            buttons=[
                dict(
                    args=[{&quot;z&quot;: [corr_matrices[0].values]}],
                    label=&quot;Pearson&quot;,
                    method=&quot;restyle&quot;
                ),
                dict(
                    args=[{&quot;z&quot;: [corr_matrices[1].values]}],
                    label=&quot;Kendall&quot;,
                    method=&quot;restyle&quot;
                ),
                dict(
                    args=[{&quot;z&quot;: [corr_matrices[2].values]}],
                    label=&quot;Spearman&quot;,
                    method=&quot;restyle&quot;
                )
            ]
        )
    ]
)

fig.update_layout(margin=dict(l=0,r=0,t=0,b=0))
fig.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div id="fig9cell-output" data-mdast-node-id="WU2TjpHduParXZtpUZqeQ" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div></div></main><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/alienx/"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">The Future of Scientific Literature: Papers Talking to Each Other</div>The Future of Scientific Literature: Papers Talking to Each Other</div></div></a></div></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="alienx/build/entry.client-VAY2DLAN.js"/><link rel="modulepreload" href="alienx/build/_shared/chunk-QDBE77SX.js"/><link rel="modulepreload" href="alienx/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="alienx/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="alienx/build/_shared/chunk-ZQ35N2EW.js"/><link rel="modulepreload" href="alienx/build/_shared/chunk-YAIQ7LUU.js"/><link rel="modulepreload" href="alienx/build/_shared/chunk-HTHE5KDW.js"/><link rel="modulepreload" href="alienx/build/_shared/chunk-JCLNTD6A.js"/><link rel="modulepreload" href="alienx/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="alienx/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="alienx/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="alienx/build/_shared/chunk-NF5NQVJX.js"/><link rel="modulepreload" href="alienx/build/_shared/chunk-5CFTM6YW.js"/><link rel="modulepreload" href="alienx/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="alienx/build/root-E6VXIW2E.js"/><link rel="modulepreload" href="alienx/build/_shared/chunk-6HHR6H4H.js"/><link rel="modulepreload" href="alienx/build/routes/$-7JHMVR4O.js"/><script>window.__remixContext = {"url":"/nlx","state":{"loaderData":{"root":{"config":{"options":{},"myst":"1.3.9","nav":[],"actions":[],"projects":[{"doi":"10.55458/neurolibre.alienx","open_access":true,"license":{"content":{"id":"CC-BY-4.0","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true,"url":"https://creativecommons.org/licenses/by/4.0/"}},"subject":"Living Preprint","numbering":{"heading_1":{"enabled":true},"heading_2":{"enabled":true},"heading_3":{"enabled":true},"heading_4":{"enabled":true},"heading_5":{"enabled":true},"heading_6":{"enabled":true}},"bibliography":["/Users/agah/Desktop/agahkarakuzu/alienx/paper.bib"],"abbreviations":{"MyST":"Markedly Structured Markdown"},"title":"The Future of Scientific Literature: Papers Talking to Each Other","subtitle":"A NeuroLibre Case Study","banner":"alienx/build/banner-d71043b95cb3b31e641f661aa1e79bb9.jpg","authors":[{"nameParsed":{"literal":"Agah Karakuzu","given":"Agah","family":"Karakuzu"},"name":"Agah Karakuzu","orcid":"0000-0001-7283-271X","affiliations":["NeuroPoly, Polytechnique Montreal, Quebec, Canada","Montreal Heart Institute, Montreal, Quebec, Canada"],"id":"contributors-myst-generated-uid-0"}],"venue":{"title":"Neurolibre"},"github":"https://github.com/agahkarakuzu/alienx","keywords":["reproducible publishing","mystmd","next-gen preprints"],"affiliations":[{"id":"NeuroPoly, Polytechnique Montreal, Quebec, Canada","name":"NeuroPoly, Polytechnique Montreal, Quebec, Canada"},{"id":"Montreal Heart Institute, Montreal, Quebec, Canada","name":"Montreal Heart Institute, Montreal, Quebec, Canada"}],"resources":["content/alienx.ipynb"],"thebe":{"binder":{"url":"https://binder-preview.neurolibre.org","provider":"github","repo":"agahkarakuzu/alienx","ref":"HEAD"}},"bannerOptimized":"alienx/build/banner-d71043b95cb3b31e641f661aa1e79bb9.webp","thumbnail":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.png","thumbnailOptimized":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.webp","exports":[],"index":"paper","pages":[{"slug":"nlx","title":"Integrative literature demonstration","description":"","date":"","thumbnail":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.png","thumbnailOptimized":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.webp","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"alienx"},"routes/$":{"config":{"options":{},"myst":"1.3.9","nav":[],"actions":[],"projects":[{"doi":"10.55458/neurolibre.alienx","open_access":true,"license":{"content":{"id":"CC-BY-4.0","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true,"url":"https://creativecommons.org/licenses/by/4.0/"}},"subject":"Living Preprint","numbering":{"heading_1":{"enabled":true},"heading_2":{"enabled":true},"heading_3":{"enabled":true},"heading_4":{"enabled":true},"heading_5":{"enabled":true},"heading_6":{"enabled":true}},"bibliography":["/Users/agah/Desktop/agahkarakuzu/alienx/paper.bib"],"abbreviations":{"MyST":"Markedly Structured Markdown"},"title":"The Future of Scientific Literature: Papers Talking to Each Other","subtitle":"A NeuroLibre Case Study","banner":"alienx/build/banner-d71043b95cb3b31e641f661aa1e79bb9.jpg","authors":[{"nameParsed":{"literal":"Agah Karakuzu","given":"Agah","family":"Karakuzu"},"name":"Agah Karakuzu","orcid":"0000-0001-7283-271X","affiliations":["NeuroPoly, Polytechnique Montreal, Quebec, Canada","Montreal Heart Institute, Montreal, Quebec, Canada"],"id":"contributors-myst-generated-uid-0"}],"venue":{"title":"Neurolibre"},"github":"https://github.com/agahkarakuzu/alienx","keywords":["reproducible publishing","mystmd","next-gen preprints"],"affiliations":[{"id":"NeuroPoly, Polytechnique Montreal, Quebec, Canada","name":"NeuroPoly, Polytechnique Montreal, Quebec, Canada"},{"id":"Montreal Heart Institute, Montreal, Quebec, Canada","name":"Montreal Heart Institute, Montreal, Quebec, Canada"}],"resources":["content/alienx.ipynb"],"thebe":{"binder":{"url":"https://binder-preview.neurolibre.org","provider":"github","repo":"agahkarakuzu/alienx","ref":"HEAD"}},"bannerOptimized":"alienx/build/banner-d71043b95cb3b31e641f661aa1e79bb9.webp","thumbnail":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.png","thumbnailOptimized":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.webp","exports":[],"index":"paper","pages":[{"slug":"nlx","title":"Integrative literature demonstration","description":"","date":"","thumbnail":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.png","thumbnailOptimized":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.webp","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"project":{"doi":"10.55458/neurolibre.alienx","open_access":true,"license":{"content":{"id":"CC-BY-4.0","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true,"url":"https://creativecommons.org/licenses/by/4.0/"}},"subject":"Living Preprint","numbering":{"heading_1":{"enabled":true},"heading_2":{"enabled":true},"heading_3":{"enabled":true},"heading_4":{"enabled":true},"heading_5":{"enabled":true},"heading_6":{"enabled":true}},"bibliography":["/Users/agah/Desktop/agahkarakuzu/alienx/paper.bib"],"abbreviations":{"MyST":"Markedly Structured Markdown"},"title":"The Future of Scientific Literature: Papers Talking to Each Other","subtitle":"A NeuroLibre Case Study","banner":"alienx/build/banner-d71043b95cb3b31e641f661aa1e79bb9.jpg","authors":[{"nameParsed":{"literal":"Agah Karakuzu","given":"Agah","family":"Karakuzu"},"name":"Agah Karakuzu","orcid":"0000-0001-7283-271X","affiliations":["NeuroPoly, Polytechnique Montreal, Quebec, Canada","Montreal Heart Institute, Montreal, Quebec, Canada"],"id":"contributors-myst-generated-uid-0"}],"venue":{"title":"Neurolibre"},"github":"https://github.com/agahkarakuzu/alienx","keywords":["reproducible publishing","mystmd","next-gen preprints"],"affiliations":[{"id":"NeuroPoly, Polytechnique Montreal, Quebec, Canada","name":"NeuroPoly, Polytechnique Montreal, Quebec, Canada"},{"id":"Montreal Heart Institute, Montreal, Quebec, Canada","name":"Montreal Heart Institute, Montreal, Quebec, Canada"}],"resources":["content/alienx.ipynb"],"thebe":{"binder":{"url":"https://binder-preview.neurolibre.org","provider":"github","repo":"agahkarakuzu/alienx","ref":"HEAD"}},"bannerOptimized":"alienx/build/banner-d71043b95cb3b31e641f661aa1e79bb9.webp","thumbnail":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.png","thumbnailOptimized":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.webp","exports":[],"index":"paper","pages":[{"slug":"nlx","title":"Integrative literature demonstration","description":"","date":"","thumbnail":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.png","thumbnailOptimized":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.webp","banner":"","bannerOptimized":"","tags":[],"level":1}]},"page":{"kind":"Notebook","sha256":"c0e2fb73d7de12d4d346637693e4d238d96c4d4b924c60ab2bed10237b8bb20a","slug":"nlx","location":"/content/nlx.ipynb","dependencies":[],"frontmatter":{"title":"Integrative literature demonstration","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"authors":[{"nameParsed":{"literal":"Agah Karakuzu","given":"Agah","family":"Karakuzu"},"name":"Agah Karakuzu","orcid":"0000-0001-7283-271X","affiliations":["NeuroPoly, Polytechnique Montreal, Quebec, Canada","Montreal Heart Institute, Montreal, Quebec, Canada"],"id":"contributors-myst-generated-uid-0"}],"doi":"10.55458/neurolibre.alienx","open_access":true,"license":{"content":{"id":"CC-BY-4.0","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true,"url":"https://creativecommons.org/licenses/by/4.0/"}},"github":"https://github.com/agahkarakuzu/alienx","subject":"Living Preprint","venue":{"title":"Neurolibre"},"numbering":{"heading_1":{"enabled":true},"heading_2":{"enabled":true},"heading_3":{"enabled":true},"heading_4":{"enabled":true},"heading_5":{"enabled":true},"heading_6":{"enabled":true}},"keywords":["reproducible publishing","mystmd","next-gen preprints"],"affiliations":[{"id":"NeuroPoly, Polytechnique Montreal, Quebec, Canada","name":"NeuroPoly, Polytechnique Montreal, Quebec, Canada"},{"id":"Montreal Heart Institute, Montreal, Quebec, Canada","name":"Montreal Heart Institute, Montreal, Quebec, Canada"}],"abbreviations":{"MyST":"Markedly Structured Markdown"},"thumbnail":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.png","thumbnailOptimized":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.webp","exports":[{"format":"ipynb","filename":"nlx.ipynb","url":"alienx/build/nlx-1b90d8a36f5054a3087ec0953ae32b69.ipynb"}]},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":5,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"NeuroLibre Day | September 27, 2024 | Montreal, Canada","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"p8OG5LJ5PB"}],"identifier":"neurolibre-day-september-27-2024-montreal-canada","label":"NeuroLibre Day | September 27, 2024 | Montreal, Canada","html_id":"neurolibre-day-september-27-2024-montreal-canada","implicit":true,"enumerator":"0.0.0.1","key":"FOyV5L6tEZ"},{"type":"heading","depth":3,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"A meta-analysis on 5 ALBERTA (ALien Brain ExtRacTion Analytics) articles","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"wCiccmqzML"}],"identifier":"a-meta-analysis-on-5-alberta-alien-brain-extraction-analytics-articles","label":"A meta-analysis on 5 ALBERTA (ALien Brain ExtRacTion Analytics) articles","html_id":"a-meta-analysis-on-5-alberta-alien-brain-extraction-analytics-articles","implicit":true,"enumerator":"0.1","key":"VPIwt71vaJ"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"link","url":"https://agahkarakuzu.github.io/alienpaper1","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The Role of Hippocampal Volume, Brain Density, and Network Efficiency in Alien Memory Function","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"FlWOMu88tv"}],"urlSource":"https://agahkarakuzu.github.io/alienpaper1","key":"qu8UrhtSp1"}],"key":"grZraRfkCr"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"link","url":"https://agahkarakuzu.github.io/alienpaper2","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Size Matters, but So Does Connectivity: The Amygdalaâ€™s Role in Emotional Intelligence","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"U2pI8p3Veo"}],"urlSource":"https://agahkarakuzu.github.io/alienpaper2","key":"BPWvDnLW0e"}],"key":"zOhB3EeLY3"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"link","url":"https://agahkarakuzu.github.io/alienpaper3","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"More Than Just Words: Temporal Cortex Volume Correlates with Language Ability","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"mbDOkt67HR"}],"urlSource":"https://agahkarakuzu.github.io/alienpaper3","key":"zEjtZGoRIb"}],"key":"DNvAIPsgIz"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"link","url":"https://agahkarakuzu.github.io/alienpaper4","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Navigating the Void: How Parietal Cortex Volume Predicts Spatial Orientation in Zero Gravity","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"ipVrv5an8A"}],"urlSource":"https://agahkarakuzu.github.io/alienpaper4","key":"KvNHXz9DuD"}],"key":"hXKngRb6DH"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"link","url":"https://agahkarakuzu.github.io/alienpaper5","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Attention is all you need, and a chunky prefrontal cortex","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"nlD1n6zdrx"}],"urlSource":"https://agahkarakuzu.github.io/alienpaper5","key":"IeyaxntKfH"}],"key":"yxKLH75iKs"}],"key":"Yc0fDPTuVT"}],"key":"fwY7LOj3rh"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"NeuroLibre cross-links","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pe4LeERgOJ"}],"identifier":"neurolibre-cross-links","label":"NeuroLibre cross-links","html_id":"neurolibre-cross-links","implicit":true,"enumerator":"0.2","key":"YT2OKepglZ"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"image","style":{"height":"80px"},"url":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.png","key":"QxnFZvU1En","urlSource":"https://github.com/neurolibre/brand/blob/main/png/neuroxlink.png?raw=true","urlOptimized":"alienx/build/c35dc4a1f0c3cdbb9d2188e00e6ac71c.webp"}],"key":"EETtYLfn24"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"NeuroxLink is a mini python package to parse ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"LRh351Xr4D"},{"type":"link","url":"https://github.com/syntax-tree/mdast","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"mdast","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"adriB2vuth"}],"urlSource":"https://github.com/syntax-tree/mdast","error":true,"key":"BL0RQeeCw0"},{"type":"text","value":", facilitating cross-paper import of article content from ","key":"qtmrB7TRy0"},{"type":"abbreviation","title":"Markedly Structured Markdown","children":[{"type":"text","value":"MyST","key":"lJYvCkWMfH"}],"key":"ydCNiCnx1h"},{"type":"text","value":" servers. It also introduces some ","key":"DVzejD8l4x"},{"type":"link","url":"https://plotly.com","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Plotly","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"FTnBhW9Wif"}],"urlSource":"https://plotly.com","key":"vzqNEieLi5"},{"type":"text","value":" functionality to work with data from interactive figures!","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"T1LFzkz8oV"}],"key":"tsbBytDwso"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"inlineCode","value":"pip install neuroxlink","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"d1CsWZF9g8"}],"key":"I1WHt7orFL"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"link","url":"https://badge.fury.io/py/neuroxlink","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"image","url":"alienx/build/2e475989b921a2bac562b9b20ada7789.svg","alt":"PyPI version","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"nkLwyiV72t","urlSource":"https://badge.fury.io/py/neuroxlink.svg"}],"urlSource":"https://badge.fury.io/py/neuroxlink","key":"NM0XotXkhn"}],"key":"zI4RqphqyJ"},{"type":"heading","depth":3,"children":[{"type":"inlineCode","value":"nlx = NeuroxLink()","key":"pPPJsmfUyn"},{"type":"break","key":"OylpzJsqCi"},{"type":"break","key":"C9xf6u7prR"},{"type":"inlineCode","value":"nlx.import_paper(\"10.55458/neurolibre.alberta1\")","key":"wdopohdKl5"}],"identifier":"nlx-neuroxlink-nlx-import-paper-10-55458-neurolibre-alberta1","label":"nlx = NeuroxLink()nlx.import_paper(\"10.55458/neurolibre.alberta1\")","html_id":"nlx-neuroxlink-nlx-import-paper-10-55458-neurolibre-alberta1","implicit":true,"enumerator":"0.3","key":"q3XN7ikRQv"}],"key":"zTdtVmwi01"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# from neuroxlink.src.neuroxlink import NeuroxLink\nfrom neuroxlink import NeuroxLink","key":"VilSsabz8D"},{"type":"output","id":"iMnuNP-9rc-WoUIM3Zr7K","data":[],"key":"B9Yfn6iZ6j"}],"key":"Bl6hVVu6t4"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"import sys\nimport os\nimport pandas as pd\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.io as pio\nimport numpy as np\npio.renderers.default = \"plotly_mimetype\"\n","visibility":"show","key":"zCVSql17um"},{"type":"output","id":"K0nSwBQr3J5spO54Z60uj","data":[],"visibility":"show","key":"kyD03bfIwT"}],"visibility":"show","key":"B25Xx4XDiL"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"1. Instantiate a ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CnohUHVskM"},{"type":"inlineCode","value":"neuroxlink","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IutmZvH88l"},{"type":"text","value":" object (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UNx1rcqfoc"},{"type":"inlineCode","value":"nlx","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"q8OVbHVi7a"},{"type":"text","value":") and import the MRI review article","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bJRIRi7mzX"}],"identifier":"id-1-instantiate-a-neuroxlink-object-nlx-and-import-the-mri-review-article","label":"1. Instantiate a neuroxlink object (nlx) and import the MRI review article","html_id":"id-1-instantiate-a-neuroxlink-object-nlx-and-import-the-mri-review-article","implicit":true,"enumerator":"0.3.1","key":"nuYSB9mCrt"}],"key":"GfZhgcIjRE"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"nlx = NeuroxLink(cdn_url=\"https://cdn.neurolibre.org\")\nnlx.import_papers(\"10.55458/neurolibre.00021\")","identifier":"fig1cell-code","enumerator":"1","html_id":"fig1cell-code","visibility":"show","key":"dkKmhhMMdJ"},{"type":"output","id":"RsgCmttt9OWFNHA5kg_IS","data":[{"output_type":"stream","name":"stdout","text":"ðŸ”— importing 10.55458/neurolibre.00021 from ðŸŒŽ https://cdn.neurolibre.org/content/mriscope/intro.json\nReproducible research practices in magnetic resonance neuroimaging: A review informed by advanced language models\n-------------------------------------\n"}],"identifier":"fig1cell-output","html_id":"fig1cell-output","visibility":"show","key":"XXinrGNpEE"}],"identifier":"fig1cell","label":"fig1cell","html_id":"fig1cell","visibility":"show","key":"xV3mVJ27Pw"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"2. Access some information about the article","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lOWCiGe4Xr"}],"identifier":"id-2-access-some-information-about-the-article","label":"2. Access some information about the article","html_id":"id-2-access-some-information-about-the-article","implicit":true,"enumerator":"0.3.2","key":"O8YK9Au4ux"}],"visibility":"show","key":"hgexQT7Tre"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"paper = nlx.papers[0]\nprint(\"\\n------------\u003e AUTHORS AND AFFILIATIONS\")\nprint(paper.get_authors(), \"\\n------------\u003e DEPENDENCIES\")\nprint(paper.get_dependencies(), \"\\n------------\u003e HEADINGS\")\nprint(paper.headings)","identifier":"fig2cell-code","enumerator":"2","html_id":"fig2cell-code","visibility":"show","key":"VN3ijT7Kgl"},{"type":"output","id":"21UJFKBnGUNSIxWD-gzU7","data":[{"output_type":"stream","name":"stdout","text":"\n------------\u003e AUTHORS AND AFFILIATIONS\n[{'nameParsed': {'literal': 'Agah Karakuzu', 'given': 'Agah', 'family': 'Karakuzu'}, 'name': 'Agah Karakuzu', 'orcid': '0000-0001-7283-271X', 'affiliations': ['NeuroPoly, Polytechnique Montreal, Quebec, Canada', 'Montreal Heart Institute, Montreal, Quebec, Canada'], 'id': 'contributors-myst-generated-uid-0'}, {'nameParsed': {'literal': 'Mathieu Boudreau', 'given': 'Mathieu', 'family': 'Boudreau'}, 'name': 'Mathieu Boudreau', 'orcid': '0000-0002-7726-4456', 'affiliations': ['NeuroPoly, Polytechnique Montreal, Quebec, Canada'], 'id': 'contributors-myst-generated-uid-1'}, {'nameParsed': {'literal': 'Nikola Stikov', 'given': 'Nikola', 'family': 'Stikov'}, 'name': 'Nikola Stikov', 'orcid': '0000-0002-8480-5230', 'affiliations': ['NeuroPoly, Polytechnique Montreal, Quebec, Canada', 'Montreal Heart Institute, Montreal, Quebec, Canada', 'Center for Advanced Interdisciplinary Research, Ss. Cyril and Methodius University, Skopje, North Macedonia'], 'id': 'contributors-myst-generated-uid-2'}] \n------------\u003e DEPENDENCIES\n[{'url': '/mriscope/literature-overview', 'label': 'fig1-cell', 'kind': 'Notebook', 'slug': 'literature-overview', 'location': '/content/literature_overview.ipynb', 'title': 'Literature overview'}, {'url': '/mriscope/gpt-insights', 'label': 'gptsession', 'kind': 'Notebook', 'slug': 'gpt-insights', 'location': '/content/gpt_insights.ipynb', 'title': 'Creating a knowledge base for a custom GPT'}, {'url': '/mriscope/word-cloud', 'label': 'fig4-cell', 'kind': 'Notebook', 'slug': 'word-cloud', 'location': '/content/word_cloud.ipynb', 'title': 'Results'}] \n------------\u003e HEADINGS\n[{'depth': 1, 'text': 'Introduction', 'identifier': 'introduction'}, {'depth': 1, 'text': 'Methodology', 'identifier': 'methodology'}, {'depth': 2, 'text': 'Mapping selected articles in the semantic landscape of reproducibility', 'identifier': 'mapping-selected-articles-in-the-semantic-landscape-of-reproducibility'}, {'depth': 2, 'text': 'Creating a knowledge base for a custom  GPT', 'identifier': 'creating-a-knowledge-base-for-a-custom-gpt'}, {'depth': 1, 'text': 'Results', 'identifier': 'results'}, {'depth': 2, 'text': 'Contextual placement of the selected articles in the landscape of reproducibility', 'identifier': 'contextual-placement-of-the-selected-articles-in-the-landscape-of-reproducibility'}, {'depth': 2, 'text': 'Custom  GPT  for reproducibility insights', 'identifier': 'custom-gpt-for-reproducibility-insights'}, {'depth': 3, 'text': 'GPT -powered summary of the reproducible magnetic resonance neuroimaging', 'identifier': 'gpt-powered-summary-of-the-reproducible-magnetic-resonance-neuroimaging'}, {'depth': 4, 'text': 'Data sharing', 'identifier': 'data-sharing'}, {'depth': 4, 'text': 'Code sharing', 'identifier': 'code-sharing'}, {'depth': 4, 'text': 'Vendor-neutrality', 'identifier': 'vendor-neutrality'}, {'depth': 4, 'text': 'Dissemination', 'identifier': 'dissemination'}, {'depth': 1, 'text': 'Discussion and Future Directions', 'identifier': 'discussion-and-future-directions'}]\n"}],"identifier":"fig2cell-output","html_id":"fig2cell-output","visibility":"show","key":"LLNjUPf3Cx"}],"identifier":"fig2cell","label":"fig2cell","html_id":"fig2cell","visibility":"show","key":"eaGMcXNeRF"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"3. Import interactive figures as structure data and create Plotly objects!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zFMFKiEKKX"}],"identifier":"id-3-import-interactive-figures-as-structure-data-and-create-plotly-objects","label":"3. Import interactive figures as structure data and create Plotly objects!","html_id":"id-3-import-interactive-figures-as-structure-data-and-create-plotly-objects","implicit":true,"enumerator":"0.3.3","key":"yhDIB7diMQ"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"First, we will check if the article published any plotly figures:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PW8wuSdYPY"}],"key":"lsulfZ10AV"}],"key":"S2yGQjfKer"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"paper.inspect_plotly_figures()","identifier":"fig3inspect-code","enumerator":"3","html_id":"fig3inspect-code","visibility":"show","key":"yyPj8pGKmr"},{"type":"output","id":"eLaepKWAD8sTPic-OjNnL","data":[{"output_type":"stream","name":"stdout","text":"These are the plotly figures I found:\n-------------------------------------\n- html-link [fig1] enumerated as (Figure 2)\n\n- html-link [fig2] enumerated as (Figure 3)\n\n- html-link [fig4] enumerated as (Figure 6)\n\n"}],"identifier":"fig3inspect-output","html_id":"fig3inspect-output","visibility":"show","key":"pmkaLhePBi"}],"identifier":"fig3inspect","label":"fig3inspect","html_id":"fig3inspect","visibility":"show","key":"xy8glVkwyS"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Perfect! There are three plotly figures that were linked using ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OobQhfYopw"},{"type":"inlineCode","value":"fig1","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hAfEOO78W7"},{"type":"text","value":", ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Pew4VQCyh5"},{"type":"inlineCode","value":"fig2","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"j2NZXUEKlY"},{"type":"text","value":", and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ysPbreU1Dt"},{"type":"inlineCode","value":"fig4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dtN98ZNnoS"},{"type":"text","value":". Lets fetch interactive Figure 1 and render it.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"k3HGgqDIGq"}],"key":"K2VVGtIF8F"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Note that ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"vIDsL6T0Zk"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"we are not performing any computation here","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ehILTjhQuc"}],"key":"QW970a02Zq"},{"type":"text","value":", instead, ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"BViKRxkYdo"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"we are taking a special chunk of the paper we imported as structured data and creating a plotly figure out of it","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"YY4eGV7QLo"}],"key":"i3cnPIRg60"},{"type":"text","value":"!","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"sKOsVv2Fov"}],"key":"O7vRmqp2Y0"}],"key":"ZD9B6R1IID"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"fig = paper.create_plotly_object_from('fig2')\nfig.show()","identifier":"fig3cell-code","enumerator":"4","html_id":"fig3cell-code","visibility":"show","key":"pQEFjWM5ns"},{"type":"output","id":"bPwf5-igjXK7fe5Xoe70h","data":[{"output_type":"display_data","metadata":{},"data":{"application/vnd.plotly.v1+json":{"content_type":"application/vnd.plotly.v1+json","hash":"26520097507b92cd7a1493840d3360c8","path":"alienx/build/26520097507b92cd7a1493840d3360c8.json"}}}],"identifier":"fig3cell-output","html_id":"fig3cell-output","visibility":"show","key":"mVYc8Q9AV2"}],"identifier":"fig3cell","label":"fig3cell","html_id":"fig3cell","visibility":"show","key":"KSXJ1pBDEC"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"4. Now, capture the data!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hVqnzdvDD0"}],"identifier":"id-4-now-capture-the-data","label":"4. Now, capture the data!","html_id":"id-4-now-capture-the-data","implicit":true,"enumerator":"0.3.4","key":"bpllDVVRF2"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"We can treat Plotly as our data standard for interactive figures. Behind the scenes, neuroxlink is parsing these plotly objects to return as the part we are interested in!","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TmSguHIp7z"}],"key":"Wm5InGjVZb"}],"key":"hnfp2kVYcs"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"data = paper.get_plotly_data('fig2')\ndata.head()","identifier":"fig4cell-code","enumerator":"5","html_id":"fig4cell-code","visibility":"show","key":"ggFZ7mKmRM"},{"type":"output","id":"vtGl-2ShhXDEwvoGAMHLt","data":[{"output_type":"execute_result","execution_count":7,"metadata":{},"data":{"text/plain":{"content":"                    x          y         z       type     mode\ntrace point                                                   \n0     0      4.861404   8.634882  7.634429  scatter3d  markers\n      1      5.929196  11.592429  6.411319  scatter3d  markers\n      2      6.237145   9.821818  7.662886  scatter3d  markers\n      3      6.317191   8.306646  7.599474  scatter3d  markers\n      4      7.110850  11.139601  8.638923  scatter3d  markers","content_type":"text/plain"},"text/html":{"content":"\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003ex\u003c/th\u003e\n      \u003cth\u003ey\u003c/th\u003e\n      \u003cth\u003ez\u003c/th\u003e\n      \u003cth\u003etype\u003c/th\u003e\n      \u003cth\u003emode\u003c/th\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003etrace\u003c/th\u003e\n      \u003cth\u003epoint\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth rowspan=\"5\" valign=\"top\"\u003e0\u003c/th\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e4.861404\u003c/td\u003e\n      \u003ctd\u003e8.634882\u003c/td\u003e\n      \u003ctd\u003e7.634429\u003c/td\u003e\n      \u003ctd\u003escatter3d\u003c/td\u003e\n      \u003ctd\u003emarkers\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e5.929196\u003c/td\u003e\n      \u003ctd\u003e11.592429\u003c/td\u003e\n      \u003ctd\u003e6.411319\u003c/td\u003e\n      \u003ctd\u003escatter3d\u003c/td\u003e\n      \u003ctd\u003emarkers\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e6.237145\u003c/td\u003e\n      \u003ctd\u003e9.821818\u003c/td\u003e\n      \u003ctd\u003e7.662886\u003c/td\u003e\n      \u003ctd\u003escatter3d\u003c/td\u003e\n      \u003ctd\u003emarkers\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e6.317191\u003c/td\u003e\n      \u003ctd\u003e8.306646\u003c/td\u003e\n      \u003ctd\u003e7.599474\u003c/td\u003e\n      \u003ctd\u003escatter3d\u003c/td\u003e\n      \u003ctd\u003emarkers\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e7.110850\u003c/td\u003e\n      \u003ctd\u003e11.139601\u003c/td\u003e\n      \u003ctd\u003e8.638923\u003c/td\u003e\n      \u003ctd\u003escatter3d\u003c/td\u003e\n      \u003ctd\u003emarkers\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e","content_type":"text/html"}}}],"identifier":"fig4cell-output","html_id":"fig4cell-output","visibility":"show","key":"sId5xCZUim"}],"identifier":"fig4cell","label":"fig4cell","html_id":"fig4cell","visibility":"show","key":"Z70MJPiYxh"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"thematicBreak","key":"XwV8rvPX8O"},{"type":"heading","depth":2,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Now we are talking! Or, is it papers talking to each other?","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Kws9KxBRSc"}],"identifier":"now-we-are-talking-or-is-it-papers-talking-to-each-other","label":"Now we are talking! Or, is it papers talking to each other?","html_id":"now-we-are-talking-or-is-it-papers-talking-to-each-other","implicit":true,"enumerator":"1","key":"YTytj7LUhD"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"inlineCode","value":"#TalkAboutInsight","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Yiuye6JxZw"}],"key":"TDOK6qnHQU"},{"type":"heading","depth":4,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Letâ€™s run a meta-analysis by importing 15 figures from 5 ALBERTA studies into this article!","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"kINUE6BLBi"}],"identifier":"lets-run-a-meta-analysis-by-importing-15-figures-from-5-alberta-studies-into-this-article","label":"Letâ€™s run a meta-analysis by importing 15 figures from 5 ALBERTA studies into this article!","html_id":"lets-run-a-meta-analysis-by-importing-15-figures-from-5-alberta-studies-into-this-article","implicit":true,"enumerator":"1.0.1","key":"niu33z4fBR"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"image","url":"alienx/build/4cabc802da2871bc3a250b0559827635.jpeg","key":"fUoIzmdXzk","urlSource":"https://github.com/agahkarakuzu/alienpaper1/blob/main/static/banner.jpg?raw=true","urlOptimized":"alienx/build/4cabc802da2871bc3a250b0559827635.webp"}],"key":"i0Ge1M2WX8"}],"visibility":"show","key":"g9TX53tR2L"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define and create a list of DOIs and figures\ndoi1 = \"10.55458/neurolibre.alberta1\"\ndoi2 = \"10.55458/neurolibre.alberta2\"\ndoi3 = \"10.55458/neurolibre.alberta3\"\ndoi4 = \"10.55458/neurolibre.alberta4\"\ndoi5 = \"10.55458/neurolibre.alberta5\"\ndois = [doi1, doi2, doi3, doi4, doi5]\nfigures = ['fig1', 'fig2', 'fig3']","visibility":"show","key":"VV8Pgy4mxE"},{"type":"output","id":"U2RDf6v3asYDtpiT0BC00","data":[],"visibility":"show","key":"Bv53t1EExD"}],"visibility":"show","key":"IC8CkCxdoK"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Import them alien papers!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qjp4wJtyJ6"}],"identifier":"import-them-alien-papers","label":"Import them alien papers!","html_id":"import-them-alien-papers","implicit":true,"enumerator":"1.1","key":"tBrit3V0Gw"}],"key":"qE31bx8shw"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"nlx.import_papers([doi1,doi2,doi3,doi4,doi5])","visibility":"show","key":"iU0qbPQD5u"},{"type":"output","id":"Bbj0Ml6i--RYIqv2Rlfiz","data":[{"output_type":"stream","name":"stdout","text":"ðŸ”— importing 10.55458/neurolibre.alberta1 from ðŸŒŽ https://cdn.neurolibre.org/content/alberta1/paper.json\nThe Role of Hippocampal Volume, Brain Density, and Network Efficiency in Alien Memory Function: ALien Brain ExtRacTion Analytics (ALBERTA) Consortium\n-------------------------------------\n"},{"output_type":"stream","name":"stdout","text":"ðŸ”— importing 10.55458/neurolibre.alberta2 from ðŸŒŽ https://cdn.neurolibre.org/content/alberta2/paper.json\nSize Matters, but So Does Connectivity: The Amygdala's Role in Emotional Intelligence: ALien Brain ExtRacTion Analytics (ALBERTA) Consortium\n-------------------------------------\nðŸ”— importing 10.55458/neurolibre.alberta3 from ðŸŒŽ https://cdn.neurolibre.org/content/alberta3/paper.json\nMore Than Just Words: Temporal Cortex Volume Correlates with Language Ability: ALien Brain ExtRacTion Analytics (ALBERTA) Consortium\n-------------------------------------\n"},{"output_type":"stream","name":"stdout","text":"ðŸ”— importing 10.55458/neurolibre.alberta4 from ðŸŒŽ https://cdn.neurolibre.org/content/alberta4/paper.json\nNavigating the Void: How Parietal Cortex Volume Predicts Spatial Orientation in Zero Gravity: ALien Brain ExtRacTion Analytics (ALBERTA) Consortium\n-------------------------------------\nðŸ”— importing 10.55458/neurolibre.alberta5 from ðŸŒŽ https://cdn.neurolibre.org/content/alberta5/paper.json\nAttention is all you need, and a chunky prefrontal cortex: ALien Brain ExtRacTion Analytics (ALBERTA) Consortium\n-------------------------------------\n"}],"visibility":"show","key":"Uv47xNh2kw"}],"visibility":"show","key":"hky0bPKElC"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"nlx.papers[doi2].inspect_plotly_figures()","visibility":"show","key":"F9cxdHnJn1"},{"type":"output","id":"JrbaflUElQS5HinnG7532","data":[{"output_type":"stream","name":"stdout","text":"These are the plotly figures I found:\n-------------------------------------\n- html-link [fig1] enumerated as (Figure 1)\n\n- html-link [fig2] enumerated as (Figure 2)\n\n- html-link [fig3] enumerated as (Figure 3)\n\n"}],"visibility":"show","key":"YTWyddfhRj"}],"visibility":"show","key":"ei3mZD66Hb"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We can dial into these figures!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VleCtmCuLy"}],"identifier":"we-can-dial-into-these-figures","label":"We can dial into these figures!","html_id":"we-can-dial-into-these-figures","implicit":true,"enumerator":"1.2","key":"C2cLRShPt7"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Interactive figures can have multiple representations of the data, which is one of the many things that makes them cool. Yet, we can still select the type of data we are interested in and use it!","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"JwwS3LVSsi"}],"key":"LsjSUT9txF"}],"visibility":"show","key":"cgT8B30XbF"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"nlx.papers[\"10.55458/neurolibre.alberta2\"].create_plotly_object_from('fig1')\n#nlx.papers[\"10.55458/neurolibre.alberta2\"].create_plotly_object_from('fig1', select_trace_type=\"histogram\")\n#nlx.papers[\"10.55458/neurolibre.alberta2\"].create_plotly_object_from('fig1', select_trace_type=\"box\")\n#nlx.papers[\"10.55458/neurolibre.alberta2\"].create_plotly_object_from('fig1', select_trace_type=\"scatter\")\n#nlx.papers[\"10.55458/neurolibre.alberta2\"].create_plotly_object_from('fig1', select_trace_type=\"scatter\",select_trace_mode=\"markers\")","visibility":"show","key":"PJQeXtlir4"},{"type":"output","id":"RrYX6wjLDNRbOl5g_oa9k","data":[{"output_type":"display_data","metadata":{},"data":{"application/vnd.plotly.v1+json":{"content_type":"application/vnd.plotly.v1+json","hash":"d2f05942926707d17df327b1a7c7767a","path":"alienx/build/d2f05942926707d17df327b1a7c7767a.json"}}}],"visibility":"show","key":"ElerOfZbvA"}],"visibility":"show","key":"dnrCILRUFp"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Start the meta analysis!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hQxw6E2X2p"}],"identifier":"start-the-meta-analysis","label":"Start the meta analysis!","html_id":"start-the-meta-analysis","implicit":true,"enumerator":"1.3","key":"osBseltUSS"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Now we are going to capture the bivariate data of 3 types of measurements (alien brain volume (ABV), alien brain density (ABD), and alien brain efficiency (ABE)) from 15 articles.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"YyPBgEk5QS"}],"key":"g8n6YGs4k7"}],"visibility":"show","key":"dGbTUblRdD"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"data = []\n\nfor doi in dois:\n    fig_data = []\n    for fig in figures:\n        print(f\"Fetching data: {fig} from {doi}\")\n        fig_data.append(nlx.papers[doi].create_plotly_object_from(fig,select_trace_type=\"scatter\",select_trace_mode=\"markers\"))\n    data.append(fig_data)\nprint(\"done\")    ","visibility":"show","key":"Ho0447P7sT"},{"type":"output","id":"-269bNHFnvknnOnfJ9MO0","data":[{"output_type":"stream","name":"stdout","text":"Fetching data: fig1 from 10.55458/neurolibre.alberta1\n"},{"output_type":"stream","name":"stdout","text":"Fetching data: fig2 from 10.55458/neurolibre.alberta1\n"},{"output_type":"stream","name":"stdout","text":"Fetching data: fig3 from 10.55458/neurolibre.alberta1\n"},{"output_type":"stream","name":"stdout","text":"Fetching data: fig1 from 10.55458/neurolibre.alberta2\n"},{"output_type":"stream","name":"stdout","text":"Fetching data: fig2 from 10.55458/neurolibre.alberta2\n"},{"output_type":"stream","name":"stdout","text":"Fetching data: fig3 from 10.55458/neurolibre.alberta2\n"},{"output_type":"stream","name":"stdout","text":"Fetching data: fig1 from 10.55458/neurolibre.alberta3\n"},{"output_type":"stream","name":"stdout","text":"Fetching data: fig2 from 10.55458/neurolibre.alberta3\n"},{"output_type":"stream","name":"stdout","text":"Fetching data: fig3 from 10.55458/neurolibre.alberta3\n"},{"output_type":"stream","name":"stdout","text":"Fetching data: fig1 from 10.55458/neurolibre.alberta4\n"},{"output_type":"stream","name":"stdout","text":"Fetching data: fig2 from 10.55458/neurolibre.alberta4\n"},{"output_type":"stream","name":"stdout","text":"Fetching data: fig3 from 10.55458/neurolibre.alberta4\n"},{"output_type":"stream","name":"stdout","text":"Fetching data: fig1 from 10.55458/neurolibre.alberta5\n"},{"output_type":"stream","name":"stdout","text":"Fetching data: fig2 from 10.55458/neurolibre.alberta5\n"},{"output_type":"stream","name":"stdout","text":"Fetching data: fig3 from 10.55458/neurolibre.alberta5\n"},{"output_type":"stream","name":"stdout","text":"done\n"}],"visibility":"show","key":"Ysh8YlkzvR"}],"visibility":"show","key":"iv6qUfv5gX"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"fig = make_subplots(rows=5, cols=3, subplot_titles=(\"ABV\", \"ABD\", \"ABE\") * 5)\n\nfor row in range(5):\n    fig.update_yaxes(title_text=f\"Score\", row=row+1, col=1)\n    fig.update_yaxes(title_text=f\"Paper {row+1}\", row=row+1, col=3, side=\"right\")\n    for col in range(3):\n        subplot_figure = data[row][col]\n        for trace in subplot_figure.data:\n            fig.add_trace(trace, row=row + 1, col=col + 1)\n            \n# Update layout\nfig.update_layout(title_text=\"Mosaic Plot of 15 figures from 5 articles\",\n                  height=800, width=800,\n                  showlegend=True,\n                  template=\"plotly_dark\")\n\n# Show the figure\nfig.show()","identifier":"fig5cell-code","enumerator":"6","html_id":"fig5cell-code","visibility":"show","key":"vWdqYQQT0z"},{"type":"output","id":"yEjju19LIPfpeYdLHN_Ml","data":[{"output_type":"display_data","metadata":{},"data":{"application/vnd.plotly.v1+json":{"content_type":"application/vnd.plotly.v1+json","hash":"a93ec1db6ae40fec1ea67abf55eab6a3","path":"alienx/build/a93ec1db6ae40fec1ea67abf55eab6a3.json"}}}],"identifier":"fig5cell-output","html_id":"fig5cell-output","visibility":"show","key":"wgZFXPoha8"}],"identifier":"fig5cell","label":"fig5cell","html_id":"fig5cell","visibility":"show","key":"q58IT2kW3D"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"column_names = {'fig1': 'vol', 'fig2': 'dens', 'fig3': 'eff'}\n\n# Initialize an empty DataFrame to store the combined data\ncombined_df = pd.DataFrame()\n\n# Loop through each DOI and figure\nfor doi in dois:\n    data = {}\n    for fig in figures:\n        # Get the data for the current DOI and figure\n        fig_data = nlx.papers[doi].get_plotly_data(fig,select_trace_type=\"scatter\",select_trace_mode=\"markers\")\n        \n        #data['score'] = fig_data['x']\n        data[column_names[fig]] = fig_data['y']\n        \n    # Create a DataFrame for the current DOI with DOI as a column\n    df = pd.DataFrame(data)\n    df['DOI'] = doi  # Add the DOI to each row\n    \n    # Append to the combined DataFrame\n    combined_df = pd.concat([combined_df, df], ignore_index=True)\n\nprint(combined_df)\n","key":"IZDmVT9slj"},{"type":"output","id":"GQu4wx5xOmXipaOLqUsPE","data":[{"output_type":"stream","name":"stdout","text":"              vol         dens          eff                           DOI\n0     1241.856859  1241.856859  1241.856859  10.55458/neurolibre.alberta1\n1     -386.257828  -386.257828  -386.257828  10.55458/neurolibre.alberta1\n2     1141.903393  1141.903393  1141.903393  10.55458/neurolibre.alberta1\n3     2335.390648  2335.390648  2335.390648  10.55458/neurolibre.alberta1\n4     -508.642687  -508.642687  -508.642687  10.55458/neurolibre.alberta1\n...           ...          ...          ...                           ...\n1995    11.076677    11.076677    11.076677  10.55458/neurolibre.alberta5\n1996  -517.365866  -517.365866  -517.365866  10.55458/neurolibre.alberta5\n1997   565.384082   565.384082   565.384082  10.55458/neurolibre.alberta5\n1998    25.591227    25.591227    25.591227  10.55458/neurolibre.alberta5\n1999   850.649546   850.649546   850.649546  10.55458/neurolibre.alberta5\n\n[2000 rows x 4 columns]\n"}],"key":"UWYQGpb0CH"}],"key":"lL7yhRX3dP"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"doi_names = {'10.55458/neurolibre.alberta1': 'Hippocampus', '10.55458/neurolibre.alberta2': 'Amygdala', '10.55458/neurolibre.alberta3': 'Temporal',\"10.55458/neurolibre.alberta4\":\"Parietal\",\"10.55458/neurolibre.alberta5\":\"Prefrontal\"}\n\n# Initialize an empty DataFrame for combining all DOIs' data\ncombined_df = pd.DataFrame()\n\n# Loop through each DOI\nfor doi in dois:\n    data = {}\n    \n    # Loop through each figure for the current DOI\n    for fig in figures:\n        # Get the data for the current DOI and figure\n        fig_data = nlx.papers[doi].get_plotly_data(fig, select_trace_type=\"scatter\", select_trace_mode=\"markers\")\n        \n        # Add data for each figure, ensure the column name is unique\n        data['score'] = fig_data['y']\n        data[column_names[fig]] = fig_data['x']  # Use the figure-specific column name\n        \n    # Convert the collected data into a DataFrame\n    df = pd.DataFrame(data)\n    \n    # Add the DOI to each row in the DataFrame\n    df['Region'] = doi_names[doi]\n    \n    # Append to the combined DataFrame\n    combined_df = pd.concat([combined_df, df], ignore_index=True)\n\n# Print or check the combined DataFrame\ncombined_df.head()\n","visibility":"show","key":"xUgwTQnGg6"},{"type":"output","id":"d10qVMMBb9FtPU62jQ6ZA","data":[{"output_type":"execute_result","execution_count":15,"metadata":{},"data":{"text/plain":{"content":"         score           vol      dens       eff       Region\n0  1241.856859 -11817.027679 -1.313845 -0.000036  Hippocampus\n1  -386.257828  -6242.624431 -0.538621 -0.000008  Hippocampus\n2  1141.903393   4761.101570  0.366497 -0.000034  Hippocampus\n3  2335.390648  10857.754856  0.948177 -0.000036  Hippocampus\n4  -508.642687  -5410.135283 -0.435989  0.000020  Hippocampus","content_type":"text/plain"},"text/html":{"content":"\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003escore\u003c/th\u003e\n      \u003cth\u003evol\u003c/th\u003e\n      \u003cth\u003edens\u003c/th\u003e\n      \u003cth\u003eeff\u003c/th\u003e\n      \u003cth\u003eRegion\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e1241.856859\u003c/td\u003e\n      \u003ctd\u003e-11817.027679\u003c/td\u003e\n      \u003ctd\u003e-1.313845\u003c/td\u003e\n      \u003ctd\u003e-0.000036\u003c/td\u003e\n      \u003ctd\u003eHippocampus\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e-386.257828\u003c/td\u003e\n      \u003ctd\u003e-6242.624431\u003c/td\u003e\n      \u003ctd\u003e-0.538621\u003c/td\u003e\n      \u003ctd\u003e-0.000008\u003c/td\u003e\n      \u003ctd\u003eHippocampus\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e1141.903393\u003c/td\u003e\n      \u003ctd\u003e4761.101570\u003c/td\u003e\n      \u003ctd\u003e0.366497\u003c/td\u003e\n      \u003ctd\u003e-0.000034\u003c/td\u003e\n      \u003ctd\u003eHippocampus\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e2335.390648\u003c/td\u003e\n      \u003ctd\u003e10857.754856\u003c/td\u003e\n      \u003ctd\u003e0.948177\u003c/td\u003e\n      \u003ctd\u003e-0.000036\u003c/td\u003e\n      \u003ctd\u003eHippocampus\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e-508.642687\u003c/td\u003e\n      \u003ctd\u003e-5410.135283\u003c/td\u003e\n      \u003ctd\u003e-0.435989\u003c/td\u003e\n      \u003ctd\u003e0.000020\u003c/td\u003e\n      \u003ctd\u003eHippocampus\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e","content_type":"text/html"}}}],"visibility":"show","key":"oKgeYgNHnx"}],"visibility":"show","key":"foKu4SipPR"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# numeric_cols = combined_df.select_dtypes(include=[np.number]).columns\n# df_zscore[numeric_cols] = (combined_df[numeric_cols] - combined_df[numeric_cols].mean())/combined_df[numeric_cols].std()\n# df_zscore[\"DOI\"] = combined_df[\"DOI\"]\n\nfig = px.scatter_matrix(combined_df,\n    dimensions=[\"vol\", \"dens\", \"eff\",\"score\"],\n    color=\"Region\", template=\"plotly_dark\")\nfig.update_traces(diagonal_visible=False)\nfig.update_layout(margin=dict(l=0,r=0,t=0,b=0))\nfig.show()","identifier":"fig6cell-code","enumerator":"7","html_id":"fig6cell-code","visibility":"show","key":"noY0eiemc2"},{"type":"output","id":"olSXY91ijWdkaBT09ykYh","data":[{"output_type":"display_data","metadata":{},"data":{"application/vnd.plotly.v1+json":{"content_type":"application/vnd.plotly.v1+json","hash":"1d1d57f9bd5f1a9b78ae1f284a73b683","path":"alienx/build/1d1d57f9bd5f1a9b78ae1f284a73b683.json"}}}],"identifier":"fig6cell-output","html_id":"fig6cell-output","visibility":"show","key":"rQPDWeDCA4"}],"identifier":"fig6cell","label":"fig6cell","html_id":"fig6cell","visibility":"show","key":"VKFICa4oB6"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"features = ['score', 'vol', 'dens', 'eff']\nX = combined_df[features].values\nX_mean = np.mean(X, axis=0)\nX_std = X - X_mean\ncov_matrix = np.cov(X_std.T)\neigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\nsorted_indices = np.argsort(eigenvalues)[::-1]\nsorted_eigenvalues = eigenvalues[sorted_indices]\nsorted_eigenvectors = eigenvectors[:, sorted_indices]\n\ntop_2_eigenvectors = sorted_eigenvectors[:, :2]\nX_pca = X_std.dot(top_2_eigenvectors)\n\npca_df = pd.DataFrame(data=X_pca, columns=['PCA1', 'PCA2'])\npca_df['Region'] = combined_df['Region']\n\nfig = px.scatter(pca_df, x='PCA1', y='PCA2', color='Region', title='PCA of Regions based on Features', template=\"plotly_dark\")\nfig.update_traces(marker=dict(size=15, opacity=0.7))\nfig.update_layout(margin=dict(l=0,r=0,t=0,b=0))\nfig.show()\n","identifier":"fig7cell-code","enumerator":"8","html_id":"fig7cell-code","visibility":"show","key":"eOjPF3WnMD"},{"type":"output","id":"BmshJvWzDD8A96tWZCUGb","data":[{"output_type":"display_data","metadata":{},"data":{"application/vnd.plotly.v1+json":{"content_type":"application/vnd.plotly.v1+json","hash":"8a8bdcdba8a5401bd28cb7e4e7a159cc","path":"alienx/build/8a8bdcdba8a5401bd28cb7e4e7a159cc.json"}}}],"identifier":"fig7cell-output","html_id":"fig7cell-output","visibility":"show","key":"Q9YkBhFkkm"}],"identifier":"fig7cell","label":"fig7cell","html_id":"fig7cell","visibility":"show","key":"vr0djrj7iO"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# If you don't believe me that the variability is coming from volume and score...\n\n# Aliens are soo linear, omg. Just stick with the ones with bigger heads :) ","visibility":"show","key":"IMOReHAVyB"},{"type":"output","id":"pBUdH9LSOSoeVQtWpwE4b","data":[],"visibility":"show","key":"N8jHnduZaS"}],"visibility":"show","key":"VaW6M3RrFa"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"fig = px.scatter(combined_df,x=\"vol\",y=\"score\",color=\"Region\",template=\"plotly_dark\")\nfig.update_traces(marker=dict(size=15, opacity=0.7))\nfig.update_layout(margin=dict(l=0,r=0,t=0,b=0))\nfig.show()","identifier":"fig8cell-code","enumerator":"9","html_id":"fig8cell-code","visibility":"show","key":"tk3EWgVUGY"},{"type":"output","id":"AxDFZ5JbpngyKTdHNFilw","data":[{"output_type":"display_data","metadata":{},"data":{"application/vnd.plotly.v1+json":{"content_type":"application/vnd.plotly.v1+json","hash":"e79a7f34e4deac307de578cb7bc08a46","path":"alienx/build/e79a7f34e4deac307de578cb7bc08a46.json"}}}],"identifier":"fig8cell-output","html_id":"fig8cell-output","visibility":"show","key":"qidecSl1Tl"}],"identifier":"fig8cell","label":"fig8cell","html_id":"fig8cell","visibility":"show","key":"kSnKDtvHxX"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"score_corr_pearson = combined_df.corr(numeric_only=True, method=\"pearson\")\nscore_corr_kendall = combined_df.corr(numeric_only=True, method=\"kendall\")\nscore_corr_spearman = combined_df.corr(numeric_only=True, method=\"spearman\")\n\n# Create a list of the correlation matrices and corresponding labels\ncorr_matrices = [score_corr_pearson, score_corr_kendall, score_corr_spearman]\nmethods = ['Pearson', 'Kendall', 'Spearman']\n\n# Initialize the first heatmap (Pearson by default)\nfig = px.imshow(corr_matrices[0],\n                color_continuous_scale='Viridis',\n                zmin=-0.5, zmax=0.9, \n                title=f'{methods[0]} Correlation Matrix', template=\"ggplot2\")\n\n# Update the layout to add the slider\nfig.update_layout(\n    updatemenus=[\n        dict(\n            type=\"buttons\",\n            direction=\"down\",\n            buttons=[\n                dict(\n                    args=[{\"z\": [corr_matrices[0].values]}],\n                    label=\"Pearson\",\n                    method=\"restyle\"\n                ),\n                dict(\n                    args=[{\"z\": [corr_matrices[1].values]}],\n                    label=\"Kendall\",\n                    method=\"restyle\"\n                ),\n                dict(\n                    args=[{\"z\": [corr_matrices[2].values]}],\n                    label=\"Spearman\",\n                    method=\"restyle\"\n                )\n            ]\n        )\n    ]\n)\n\nfig.update_layout(margin=dict(l=0,r=0,t=0,b=0))\nfig.show()","identifier":"fig9cell-code","enumerator":"10","html_id":"fig9cell-code","visibility":"show","key":"tL5vRrMbTV"},{"type":"output","id":"WU2TjpHduParXZtpUZqeQ","data":[{"output_type":"display_data","metadata":{},"data":{"application/vnd.plotly.v1+json":{"content":"{\"data\":[{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"score\",\"vol\",\"dens\",\"eff\"],\"y\":[\"score\",\"vol\",\"dens\",\"eff\"],\"z\":[[1,0.357220083237977,-0.0030324597780506863,0.05521548229179128],[0.357220083237977,1,0.5257484020505997,-0.008176709484727018],[-0.0030324597780506863,0.5257484020505997,1,-0.014807596249208112],[0.05521548229179128,-0.008176709484727018,-0.014807596249208112,1]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\u003cbr\u003ey: %{y}\u003cbr\u003ecolor: %{z}\u003cextra\u003e\u003c/extra\u003e\"}],\"layout\":{\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(51,51,51)\"},\"error_y\":{\"color\":\"rgb(51,51,51)\"},\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"baxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"colorscale\":{\"sequential\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"sequentialminus\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]]},\"colorway\":[\"#F8766D\",\"#A3A500\",\"#00BF7D\",\"#00B0F6\",\"#E76BF3\"],\"font\":{\"color\":\"rgb(51,51,51)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(237,237,237)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(237,237,237)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0,1],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0,1],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorscale\":[[0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1,\"#fde725\"]],\"cmin\":-0.5,\"cmax\":0.9},\"title\":{\"text\":\"Pearson Correlation Matrix\"},\"updatemenus\":[{\"buttons\":[{\"args\":[{\"z\":[[[1,0.357220083237977,-0.0030324597780506863,0.05521548229179128],[0.357220083237977,1,0.5257484020505997,-0.008176709484727018],[-0.0030324597780506863,0.5257484020505997,1,-0.014807596249208112],[0.05521548229179128,-0.008176709484727018,-0.014807596249208112,1]]]}],\"label\":\"Pearson\",\"method\":\"restyle\"},{\"args\":[{\"z\":[[[1,0.12440820410205103,0.035130565282641316,0.26829814907453725],[0.12440820410205103,1,0.6609774887443722,-0.034947473736868434],[0.035130565282641316,0.6609774887443722,1,0.0034787393696848424],[0.26829814907453725,-0.034947473736868434,0.0034787393696848424,1]]]}],\"label\":\"Kendall\",\"method\":\"restyle\"},{\"args\":[{\"z\":[[[1,0.174215016053754,0.06518934129733532,0.3763652515913129],[0.174215016053754,1,0.8013455123363781,-0.06931424332856083],[0.06518934129733532,0.8013455123363781,1,-0.025736991434247857],[0.3763652515913129,-0.06931424332856083,-0.025736991434247857,1]]]}],\"label\":\"Spearman\",\"method\":\"restyle\"}],\"direction\":\"down\",\"type\":\"buttons\"}],\"margin\":{\"l\":0,\"r\":0,\"t\":0,\"b\":0}},\"config\":{\"plotlyServerURL\":\"https://plot.ly\"}}","content_type":"application/vnd.plotly.v1+json"}}}],"identifier":"fig9cell-output","html_id":"fig9cell-output","visibility":"show","key":"cG4eVf0Kmz"}],"identifier":"fig9cell","label":"fig9cell","html_id":"fig9cell","visibility":"show","key":"sPW5nFn5H6"}],"key":"OJku9jFV6n"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"The Future of Scientific Literature: Papers Talking to Each Other","url":"/","group":"The Future of Scientific Literature: Papers Talking to Each Other"}}},"domain":"http://localhost:3000"}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "alienx/build/manifest-784CAFDF.js";
import * as route0 from "alienx/build/root-E6VXIW2E.js";
import * as route1 from "alienx/build/routes/$-7JHMVR4O.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("alienx/build/entry.client-VAY2DLAN.js");</script></body></html>